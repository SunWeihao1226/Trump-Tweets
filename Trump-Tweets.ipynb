{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8954c5-b70a-455d-8e0e-f30a751c844d",
   "metadata": {},
   "source": [
    "# Predicting whether Trump's Tweets Will Have Vast Retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e36acb-efea-4095-8f43-50a419561237",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Donald John Trump, as known as the 45th president of the United States served from 2017 to 2021, extremely prefers to post tweets on Twitter. Although his Twitter account is suspended due to unfriendly content, some of the posts he already published were wildly retweeted. In the dataset [Trump Tweets](https://www.kaggle.com/austinreese/trump-tweets) on Kaggle, his tweets before June 2020 were recorded. In this project, an objective data analysis using machine learning techniques will be performed to solve one particular question: **How to predict whether a tweet posted by Donald Trump will go \"viral\" (i.e. Having more than 10,000 retweets)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc7e39-b8c7-4a28-8fc0-3c89f02c11f5",
   "metadata": {},
   "source": [
    "## IDE\n",
    "\n",
    "First of all, importing packages that are used for this project, and import the Trump Tweets dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ed8f43-8b09-4b34-a2a7-29dac8c25980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6102278-4ce7-49a5-8e23-184e638447ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"realdonaldtrump.csv\", index_col=0)\n",
    "y = tweets_df[\"retweets\"] > 10_000\n",
    "X = tweets_df[\"content\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=321)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723654d5-f49b-42c7-b220-035183821eb8",
   "metadata": {},
   "source": [
    "Since we are predicting the \"viral\" tweets, and only the contents of the tweets are needed, we modified the targets and features set. Other columns in the original dataset are ignored. As a result, the data is already clean enough for further analysis. Moreover, we split the training and testing data for further assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9013a7e6-e97c-475c-8782-e01db887fecc",
   "metadata": {},
   "source": [
    "## Applying the Models\n",
    "\n",
    "Since the values in the dataset are texts, `CountVectorizer`, which is a common technique to deal with text will be used. Since there is only one column in the `X` set, preprocessing techniques are not needed in this dataset. To obtain a baseline result, `DummyClassifier` will be applied first, since it is the most simple classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b14d4e84-0193-470f-ba52-b27507ad69e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.438671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.095556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.738543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.738543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DummyClassifier\n",
       "fit_time            0.438671\n",
       "score_time          0.095556\n",
       "test_score          0.738543\n",
       "train_score         0.738543"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvec = CountVectorizer(stop_words=\"english\")\n",
    "dm = DummyClassifier()\n",
    "pipe_dm = make_pipeline(countvec, dm)\n",
    "cross_val_results_dm = pd.DataFrame(\n",
    "    cross_validate(pipe_dm, X_train, y_train, return_train_score=True)\n",
    ")\n",
    "dummy_result = pd.DataFrame(cross_val_results_dm.mean())\n",
    "dummy_result.columns = [\"DummyClassifier\"]\n",
    "dummy_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eec070-b238-4960-bb7e-c0cce49971f8",
   "metadata": {},
   "source": [
    "The test score of `DummyClassifier` is around 74%, which means that there are 74% of tweets in the training set are \"viral\", while the rest are not \"viral\". It seems not bad using the baseline model. However, there is one problem with `DummyClassifier` model, which is that it does not need the `CountVectorizer` because it simply predicts by looking at the most frequent value in the training set. So, some more advanced models are required to solve the problem. Here, we use the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d9c0f9b-be1a-499b-bcae-6590c59ed2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>1.117634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.094519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.897890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.967045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Logistic Regression\n",
       "fit_time                1.117634\n",
       "score_time              0.094519\n",
       "test_score              0.897890\n",
       "train_score             0.967045"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "pipe_lr = make_pipeline(countvec, lr)\n",
    "cross_val_results = pd.DataFrame(\n",
    "    cross_validate(pipe_lr, X_train, y_train, return_train_score=True)\n",
    ")\n",
    "lr_result = pd.DataFrame(cross_val_results.mean())\n",
    "lr_result.columns = [\"Logistic Regression\"]\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2108f8d5-067f-47c8-90c6-71b48f4564b1",
   "metadata": {},
   "source": [
    "As shown in the result, the Logistic Regression model performs better than the baseline model, since it has a much higher test score. It is a clear improvement of the baseline model. To examine it further, some probability scores will be assessed later at the end of this project to evaluate the performance of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec2be8-631f-4bde-a5a5-90ce87a3e808",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning and Coefficients\n",
    "\n",
    "In the previous part, we applied the Logistic Regression model without choosing the best hyperparameter. To obtain a more accurate result, we will run the hyperparameter optimization to obtain the best hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011de1bd-1a07-441d-b106-28eaade481a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n"
     ]
    }
   ],
   "source": [
    "max_features = [10, 100, 1000, 10_000, 100_000]\n",
    "C_vals = 10.0 ** np.arange(-1.5, 2, 0.5)\n",
    "param_grid = {\n",
    "    \"countvectorizer__max_features\": max_features,\n",
    "    \"logisticregression__C\": C_vals,\n",
    "}\n",
    "\n",
    "pipe_tune = make_pipeline(CountVectorizer(stop_words=\"english\"), LogisticRegression(max_iter=1000))\n",
    "grid_search = GridSearchCV(pipe_tune, param_grid, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04fb2f5e-4e8a-4b45-99f6-0eac4baf696d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__max_features': 100000, 'logisticregression__C': 1.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cfe2a54-896c-4590-ae8a-c857ce7f5cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8978900824847041"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c16bb8-65b9-4a75-806a-ce23bf020e57",
   "metadata": {},
   "source": [
    "There is a slight improvement of the test score, and the best hyperparameters are shown above. Now training the Logistic Regression model again applying the hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc9ba00-1ceb-413c-92a7-ece35d1c7afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(max_features=100000, stop_words='english')),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_best = make_pipeline(\n",
    "        CountVectorizer(stop_words=\"english\", max_features=100000),\n",
    "        LogisticRegression(max_iter=1000, C=1.0),\n",
    "    )\n",
    "pipe_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35180b14-f6cf-4edd-a855-c0e2e5f67bdc",
   "metadata": {},
   "source": [
    "Furthermore, we can find the words with the highest and lowest coefficients in the training set, that is, words that mostly and least determine whether the tweets is \"viral\" or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "def74806-7085-4d82-bafb-ec3afa468858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>harassment</th>\n",
       "      <td>2.731876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mini</th>\n",
       "      <td>2.712430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>2.692801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2.434258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transcripts</th>\n",
       "      <td>2.380516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1pic</th>\n",
       "      <td>-2.295077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump2016</th>\n",
       "      <td>-2.316185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barackobama</th>\n",
       "      <td>-2.565437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump2016pic</th>\n",
       "      <td>-2.637216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realdonaldtrump</th>\n",
       "      <td>-3.116922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40965 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Coefficient\n",
       "harassment          2.731876\n",
       "mini                2.712430\n",
       "fake                2.692801\n",
       "coronavirus         2.434258\n",
       "transcripts         2.380516\n",
       "...                      ...\n",
       "1pic               -2.295077\n",
       "trump2016          -2.316185\n",
       "barackobama        -2.565437\n",
       "trump2016pic       -2.637216\n",
       "realdonaldtrump    -3.116922\n",
       "\n",
       "[40965 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_from_pipe = pipe_best.named_steps[\"countvectorizer\"]\n",
    "lr_from_pipe = pipe_best.named_steps[\"logisticregression\"]\n",
    "\n",
    "feature_names = np.array(vec_from_pipe.get_feature_names_out())\n",
    "coeffs = lr_from_pipe.coef_.flatten()\n",
    "word_coeff_df = pd.DataFrame(coeffs, index=feature_names, columns=[\"Coefficient\"])\n",
    "word_coeff_df.sort_values(by=\"Coefficient\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee1e70-94c8-422d-a529-451af286204e",
   "metadata": {},
   "source": [
    "We have abstracted the 5 words with the highest coefficient, and the 5 words with the lowest coefficient in the table shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f2894-9b6e-4043-a272-ec19b98e8732",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "In this part, we will evaluate the tuned Logistic Regression model using the testing data. To examine it more, we will also generate probability scores, and find the most \"viral\" tweet in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff166c63-35d9-41d9-ae9c-2d356632b120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score of the tuned Logistic Regression model: 0.899243\n"
     ]
    }
   ],
   "source": [
    "print(\"Test score of the tuned Logistic Regression model: %f\" % (pipe_best.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85fc8947-1070-48d3-8fc5-229fc98157e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 'viral' tweet in the testing set is: 'Corrupt politician Adam Schiff wants people from the White House to testify in his and Pelosi’s disgraceful Witch Hunt, yet he will not allow a White House lawyer, nor will he allow ANY of our requested witnesses. This is a first in due process and Congressional history!'\n"
     ]
    }
   ],
   "source": [
    "viral_probs = pipe_best.predict_proba(X_test)[:,1]\n",
    "highest_prob = np.argmax(viral_probs)\n",
    "print(\"The most 'viral' tweet in the testing set is: '%s'\" % X_test.iloc[highest_prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c5aec6f-da10-44de-a89d-2078d2136405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "associated probability is 0.9999999325332923\n"
     ]
    }
   ],
   "source": [
    "print(\"associated probability is \" + str(viral_probs[highest_prob]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81205f2a-e4f4-4256-adb5-ea916af7d921",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "In this project, the Logistic Regression model is used to predict whether a tweet is \"viral\" or not, and its performance is generally satisfied. The final prediction accuracy is 89.9243%, which is high in such a text predicting problem. We also predicted the most \"viral\" tweet in the testing set, and the probability of such prediction is relatively high (close to 1). In conclusion, the Logistic Regression model with the `CountVectorizer` performs well in predicting whether a tweet has vast retweets or not. It is worth using in solving similar problems in the real words, such as analyzing which post is likely to spread widely on the internet, and it is useful to deal with public relation problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
